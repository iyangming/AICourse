# 昇思MindSpore技术公开课 - 大模型专题

如果你想要学习大模型背后的原理，了解前沿技术；渴望自己动手构建自己的语言模型，那就请不要错过我们大模型技术公开课！4.15起，每周六14:00-15:30，我们在b站等候你的到来₍ᐢ..ᐢ₎♡

## 【新增】#为MindSpore打Call#课程学习打榜活动

除了可以免费使用启智社区提供的高达8卡NPU资源外，为了帮助开发者们更好的学习大模型专题课程内容, 昇思MindSpore联合OpenI启智社区通过"我为开源打榜狂"举办一系列学习打榜活动, 为大家设定一系列加分任务, 鼓励大家进行动手实践，输出沉淀优质内容。

### 加分任务

**任务1**：基于[动手学深度学习项目](https://openi.pcl.ac.cn/mindspore-courses/d2l-mindspore)或者昇思MindSpore技术公开课大模型专题的[代码仓](https://openi.pcl.ac.cn/mindspore-courses/step_into_chatgpt)在平台输出学习笔记或心得，并将链接通过在原项目（即动手学深度学习项目或大模型专题代码仓）提交Issue（即创建任务）的形式，由助教进行审核通过后的优质内容可在挑战升级榜中加20积分/篇；在外部平台（如知乎、csdn等）进行的分享，将链接通过在项目提交Issue，由助教进行审核通过后的优质内容加10积分/篇。心得提交地址：请根据课程提交至对应项目 [昇思MindSpore版《动手学深度学习》课程笔记](https://openi.pcl.ac.cn/mindspore-courses/d2l-mindspore/issues/1) 或 [昇思MindSpore技术公开课大模型专题课程——学习笔记](https://openi.pcl.ac.cn/mindspore-courses/step_into_chatgpt/issues/3)

**任务2** 根据动手学深度学习项目课程内容，或昇思MindSpore技术公开课大模型专题的内容，在启智社区输出相关代码项目，经助教评审通过后可加20积分/项目。动手学深度学习项目可尝试更换数据集，修改模型结构，模型调参优化等方式开展代码实践，昇思MindSpore技术公开课大模型专题课程可参考每节课程回顾中的课程实践建议。提交地址：请根据课程提交至对应项目  [昇思MindSpore版《动手学深度学习》代码实践](https://openi.pcl.ac.cn/mindspore-courses/d2l-mindspore/issues/2) 或 [昇思MindSpore技术公开课大模型专题课程——代码实践](https://openi.pcl.ac.cn/mindspore-courses/step_into_chatgpt/issues/4)

### 积分用途

开源打榜活动将依据用户的积分数量进行排名, 根据排名情况进行300-1000元阶梯性的**现金奖励** ，具体活动方案参见：[第八期打榜活动](https://openi.org.cn/index.php?a=lists&c=index&catid=233&m=content)

## 仓库地址

- [Github](https://github.com/mindspore-courses/step_into_chatgpt)
- [OpenI](https://openi.pcl.ac.cn/mindspore-courses/step_into_chatgpt)

推荐使用OpenI平台，直接使用启智云脑算力执行公开课代码。

## 课程介绍

《昇思MindSpore技术公开课》为昇思MindSpore与启智社区联合推出的系列课程。本次专题课程聚焦大模型领域，注重大模型代码实践。课程中，你将从实践的角度出发，通过复现ChatGPT的实现过程，手把手地搭建一个简易版的“ChatGPT”，从而深入了解大型语言模型的构建和原理。本课程将理论与代码进行融合，系统地逐步揭秘ChatGPT、GPT-4背后支持的大型语言类模型（Large Language Model， LLM），旨在让学生深入了解大模型领域知识的同时，真正切实地参与到大模型相关的任务实践中来。

课程内容之外，我们同时开展大模型访谈活动，邀请业界专家讨论大型语言模型领域的技术趋势与行业应用。此外，我们还提供了多样的社区活动与社区实习，让你能够巩固课程所学知识，深入拓展自己的能力，还可以获得实践证书。感兴趣的同学还可以参加昇腾AI创新大赛的大模型比赛，深入了解行业场景。

## 课程安排

| 课程事项 |  |
|----------|----------|
| 开课日期 | (预计) 2023/4/15 - 2023/6/17|
| 直播时间 | 每周六14：00 - 15：30 |
| 直播平台 | B站 |
| 课程回放 | [B站 MindSpore官方账号](https://space.bilibili.com/526894060) |
| 算力平台 | [启智OpenI平台](https://openi.pcl.ac.cn/) |

## 课前准备

| 任务 | 内容 |
|----------|----------|
| MindSpore的安装与使用 | 登录MindSpore官网，参考[安装指南](https://www.mindspore.cn/install)安装MindSpore，并学习[入门教程](https://www.mindspore.cn/tutorials/zh-CN/r2.0.0-alpha/index.html) <br> 也可以通过[应用实践案例](https://www.mindspore.cn/tutorials/application/zh-CN/r2.0.0-alpha/index.html)，简单了解MindSpore端到端模型实践 |
| 启智社区算力使用 | 登录启智OpenI AI协作平台，参与小白训练营，学习入门教程 <br> 视频教程可参考量子位推文 - [单卡就能运行的AI画画模型，小白也能看懂的教程来了](https://mp.weixin.qq.com/s/BI2wqrp-xnBYE60pDBZAbA) |
| 课前预习 | 进入[mindspore-courses/step_into_chatgpt 代码仓](https://github.com/mindspore-courses/step_into_chatgpt)，浏览课程进行预习 |
| 关注B站直播间 | 担心错过直播的同学可以关注[B站MindSpore官方账号](https://space.bilibili.com/526894060?spm_id_from=333.337.0.0) |

## 前序课程

有的小伙伴反馈，如果基础不太适合参与大模型学习怎么办，我们这里也为深度学习基础相对薄弱的小伙伴准备了前序课程————昇思MindSpore版《动手学深度学习》。

《动手学深度学习》这本书由李沐等人主导从零开始教授深度学习，覆盖四大类模型：多层感知机、卷积神经网络、循环神经网络、和注意力机制，以及深度学习中的两大应用领域—计算机视觉和自然语言处理—中的典型任务。开发者们只需要有基础的Python变成和数学基础即可参与学习，不仅可以学习模型算法，教材中还提供了大量可运行的代码，供大家进行实践。

同时，为帮助小伙伴们更好地学习知识，昇思MindSpore联合OpenI启智社区通过“我为开源打榜狂”举办了学习任务，我们为大家设置了一系列打分任务，详情请见上方 **【新增】#为MindSpore打Call#课程学习打榜活动**。


## 课程内容

> 最新通知： 考虑到4月29日为五一假期，小伙伴们可能会有自己的安排，同时也为了给大家提供更加优质的课程内容。经过综合考量，我们决定将4月29日的GPT课程后移一周，调整至5月6日开课，其余课程时间安排保持不变。特此通知，感谢大家的理解（鞠躬）。

| 章节序号 | 章节名称 | 课程简介                                        | 视频 | 课件及代码 | 知识点总结 |
|:----:|:----:|:--------------------------------------------|:----:|:----:|:----:|
| 第一讲 | Transformer | Multi-head self-attention原理。Masked self-attention的掩码处理方式。基于Transformer的机器翻译任务训练。 | [link](https://www.bilibili.com/video/BV16h4y1W7us/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f4290) | [link](./Season1.step_into_chatgpt/1.Transformer/) | [link](./Season1.step_into_chatgpt/0.Course-Review/1-Transformer.md) |
| 第二讲 | BERT | 基于Transformer Encoder的BERT模型设计：MLM和NSP任务。BERT进行下游任务微调的范式。 | [link](https://www.bilibili.com/video/BV1xs4y1M72q/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | [link](./Season1.step_into_chatgpt/2.BERT/) | [link](./Season1.step_into_chatgpt/0.Course-Review/2-BERT.md) |
| 第三讲 | GPT | 基于Transformer Decoder的GPT模型设计：Next token prediction。GPT下游任务微调范式。 | [link](https://www.bilibili.com/video/BV1Gh411w7HC/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | [link](./Season1.step_into_chatgpt/3.GPT/) | [link](./Season1.step_into_chatgpt/0.Course-Review/3-GPT.md) |
| 第四讲 | GPT2 | GPT2的核心创新点，包括Task Conditioning和Zero shot learning；模型实现细节基于GPT1的改动。 |  [link](https://www.bilibili.com/video/BV1Ja4y1u7xx/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | [link](./Season1.step_into_chatgpt/4.GPT2/) | [link](./Season1.step_into_chatgpt/0.Course-Review/4-GPT2.md) |
| 第五讲 | MindSpore自动并行 | 以MindSpore分布式并行特性为依托的数据并行、模型并行、Pipeline并行、内存优化等技术。 |  [link](https://www.bilibili.com/video/BV1VN41117AG/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | [link](./Season1.step_into_chatgpt/5.Parallel/) | [link](./Season1.step_into_chatgpt/0.Course-Review/5-Parallel.md) |
| 第六讲 | 代码预训练 | 代码预训练发展沿革。Code数据的预处理。CodeGeex代码预训练大模型。      |  [link](https://www.bilibili.com/video/BV1Em4y147a1/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | [link](./Season1.step_into_chatgpt/6.CodeGeeX/) | [link](./Season1.step_into_chatgpt/0.Course-Review/6-CodeGeex.md) |
| 第七讲 | Prompt Tuning | Pretrain-finetune范式到Prompt tuning范式的改变。Hard prompt和Soft prompt相关技术。只需要改造描述文本的prompting。 | [link](https://www.bilibili.com/video/BV1Wg4y1K77R/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | [link](./Season1.step_into_chatgpt/7.Prompt/) | [link](./Season1.step_into_chatgpt/0.Course-Review/7-Prompt.md) |
| 第八讲 | 多模态预训练大模型 | 紫东太初多模态大模型的设计、数据处理和优势；语音识别的理论概述、系统框架和现状及挑战。 | [link](https://www.bilibili.com/video/BV1wg4y1K72r/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | / | / |
| 第九讲 | Instruct Tuning | Instruction tuning的核心思想：让模型能够理解任务描述（指令）。Instruction tuning的局限性：无法支持开放域创新性任务、无法对齐LM训练目标和人类需求。Chain-of-thoughts：通过在prompt中提供示例，让模型“举一反三”。 | [link](https://www.bilibili.com/video/BV1cm4y1e7Cc/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | [link](./Season1.step_into_chatgpt/8.Instruction/) | [link](./Season1.step_into_chatgpt/0.Course-Review/8-Instruction.md) |
| 第十讲 | RLHF | RLHF核心思想：将LLM和人类行为对齐。RLHF技术分解：LLM微调、基于人类反馈训练奖励模型、通过强化学习PPO算法实现模型微调。 | [link](https://www.bilibili.com/video/BV15a4y1c7dv/?spm_id_from=333.999.0.0&vd_source=eb3a45e6eb4dccc5795f97586b78f429) | [link](./Season1.step_into_chatgpt/9.RLHF/) | 更新中 |

## 课后活动

昇思MindSpore社区活动入口：[Link](https://gitee.com/mindspore/community/issues/I6Q9H4)