{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2363a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_preprocess_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0714b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hidden_layers=[128, 64], optimizer='adam'):\n",
    "    optimizer_dict = {\n",
    "        'adam': Adam(),\n",
    "        'sgd': SGD(),\n",
    "        'rmsprop': RMSprop()\n",
    "    }\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "    for units in hidden_layers:\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=optimizer_dict.get(optimizer, Adam()),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate(hidden_layers, optimizer, epochs=10, batch_size=128):\n",
    "    (x_train, y_train), (x_test, y_test) = load_preprocess_data()\n",
    "    \n",
    "    model = build_model(hidden_layers, optimizer)\n",
    "    \n",
    "    print(f\"\\nTraining model with layers {hidden_layers} and optimizer '{optimizer}'\")\n",
    "    \n",
    "    start_train = time.time()\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=2)\n",
    "    end_train = time.time()\n",
    "    \n",
    "    start_test = time.time()\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    end_test = time.time()\n",
    "    \n",
    "    train_time = end_train - start_train\n",
    "    test_time = end_test - start_test\n",
    "    \n",
    "    print(f\"Train time: {train_time:.2f} s, Test time: {test_time:.2f} s\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return model, history, train_time, test_time, test_loss, test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history, title_suffix=''):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'Loss Curve {title_suffix}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title(f'Accuracy Curve {title_suffix}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252db0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiments = [\n",
    "    {'hidden_layers': [64], 'optimizer': 'adam'},\n",
    "    {'hidden_layers': [128, 64], 'optimizer': 'adam'},\n",
    "    {'hidden_layers': [256, 128, 64], 'optimizer': 'adam'},\n",
    "    {'hidden_layers': [128, 64], 'optimizer': 'sgd'},\n",
    "    {'hidden_layers': [128, 64], 'optimizer': 'rmsprop'},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp in experiments:\n",
    "    model, history, train_time, test_time, test_loss, test_acc = train_and_evaluate(\n",
    "        exp['hidden_layers'], exp['optimizer'], epochs=10)\n",
    "    \n",
    "    plot_history(history, title_suffix=f\"Layers:{exp['hidden_layers']} Optimizer:{exp['optimizer']}\")\n",
    "    \n",
    "    results.append({\n",
    "        'hidden_layers': exp['hidden_layers'],\n",
    "        'optimizer': exp['optimizer'],\n",
    "        'train_time': train_time,\n",
    "        'test_time': test_time,\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_acc,\n",
    "        'model': model,\n",
    "        'history': history\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b15e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_result = max(results, key=lambda x: x['test_accuracy'])\n",
    "print(\"\\n=== Best Model Summary ===\")\n",
    "print(f\"Layers: {best_result['hidden_layers']}\")\n",
    "print(f\"Optimizer: {best_result['optimizer']}\")\n",
    "print(f\"Test Accuracy: {best_result['test_accuracy']:.4f}\")\n",
    "print(f\"Test Loss: {best_result['test_loss']:.4f}\")\n",
    "print(f\"Training Time: {best_result['train_time']:.2f} s\")\n",
    "\n",
    "best_result['model'].save('best_mnist_model.h5')\n",
    "print(\"Best model saved as 'best_mnist_model.h5'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de140944",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\"\"\n",
    "=== Result Analysis ===\n",
    "1. 增加隐含层数和节点数一般能提升准确率，但训练时间也随之增加。\n",
    "2. Adam优化器收敛较快且效果稳定；SGD收敛较慢但有助于泛化。\n",
    "3. 过深或过宽的网络可能导致过拟合或训练时间过长。\n",
    "4. 交叉熵损失与准确率曲线能够有效监控模型训练过程和质量。\n",
    "5. 选择合适的网络结构和优化器对模型性能影响显著。\n",
    "\"\"\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
